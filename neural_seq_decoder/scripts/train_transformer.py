import os
import torch
import numpy as np

from transformer_decoder.transformer_trainer import trainModel

from transformer_decoder.bit import BiT_Phoneme


model_name = f"transformer_baseline_v1"
output_dir = "/mnt/data/jeon/baseline_logs/transformerBaselinev1"
dataset_path = "/mnt/data/jeon/competitionData/ptDecoder_ctc"
    
    # Create config dictionary
args = {
    'seed': 42,
    'outputDir': output_dir,
    'datasetPath': dataset_path,
    'modelName': model_name,
    'maxDay': None,
    'patch_size': (5, 256),
    'dim': 384,
    'depth': 5,
    'heads': 6,
    'mlp_dim_ratio': 4,
    'dim_head': 64,
    'T5_style_pos': True,
    'nClasses': 40,
    'whiteNoiseSD': 0.8,
    'gaussianSmoothWidth': 2.0,
    'constantOffsetSD': 0.2,
    'l2_decay': 1e-5,
    'input_dropout': 0.1,
    'dropout': 0.35,
    'AdamW': True,
    'learning_scheduler': 'multistep',
    'lrStart': 0.001,
    'lrEnd': 0.001,
    'batchSize': 64,
    'beta1': 0.90,
    'beta2': 0.999,
    'n_epochs': 250,
    'milestones': [150],
    'gamma': 0.1,
    'extra_notes': "",
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'load_pretrained_model': "",
    'start_epoch': 0,
    'mask_token_zero' : False,
    'num_masks_channels' : 0, # number of masks per grid
    'max_mask_channels' : 0, # maximum number of channels to mask per mask
    'max_mask_pct' : 0.075, 
    'num_masks' : 20,
    'consistency': False, 
    'consistency_scalar': 0.2,
    'interCTC': True,
    'interWeight': 0.3,
    'use_conformer': None,
}

print(f"Using dataset: {args['datasetPath']}")

# Warn if output directory exists
if os.path.exists(args['outputDir']):
    print(f"Output directory '{args['outputDir']}' already exists. Press 'c' to continue.")
    breakpoint()
        
torch.manual_seed(args["seed"])
np.random.seed(args["seed"])

# Instantiate model
model = BiT_Phoneme(
    patch_size=args['patch_size'],
    dim=args['dim'],
    dim_head=args['dim_head'],
    nClasses=args['nClasses'],
    depth=args['depth'],
    heads=args['heads'],
    mlp_dim_ratio=args['mlp_dim_ratio'],
    dropout=args['dropout'],
    input_dropout=args['input_dropout'],
    gaussianSmoothWidth=args['gaussianSmoothWidth'],
    T5_style_pos=args['T5_style_pos'],
    max_mask_pct=args['max_mask_pct'],
    num_masks=args['num_masks'], 
    mask_token_zeros=args['mask_token_zero'], 
    num_masks_channels=args['num_masks_channels'], 
    max_mask_channels=args['max_mask_channels'],
    consistency = args['consistency'],
    interCTC = args['interCTC'],
    use_conformer = args['use_conformer'],
).to(args['device'])

# Load pretrained model if specified
if args['load_pretrained_model']:
    ckpt_path = os.path.join(args['load_pretrained_model'], 'modelWeights')
    model.load_state_dict(torch.load(ckpt_path, map_location=args['device']), strict=True)
    print(f"Loaded pretrained model from {ckpt_path}")
        
    
# Train
trainModel(args, model)